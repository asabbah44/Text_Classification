{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SVM_BOW.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asabbah44/Text_Classification/blob/main/SVM_BOW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0RAGduMw4Mi",
        "outputId": "360b9d82-0460-4493-8409-a5e8a4e5f106"
      },
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from nltk import sent_tokenize\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "import xml\n",
        "\n",
        "import csv\n",
        "import ast\n",
        "import logging\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix,recall_score ,precision_score, f1_score, average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import drive\n",
        "%matplotlib inline\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "import statistics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZj7Ti89S0qj",
        "outputId": "b4cdf71a-5d84-4a71-cf94-58a4fb569c30"
      },
      "source": [
        "nltk.download('stopwords')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "71CJEShkQmDH",
        "outputId": "6e240d5e-a269-43d7-8cc5-50397f3a7fdb"
      },
      "source": [
        "drive.mount(\"/content/drive\")   # Mount Googledrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RCQACPUB1qHB",
        "outputId": "7dad9efc-4482-4e04-d4c7-597ccba061d7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AUK_U-JexBKV"
      },
      "source": [
        "df1 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/dataset.csv')\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/mydataset.csv')\n",
        "\n",
        "\n",
        "df1 = pd.DataFrame(df1, columns = ['commenttext','label'])\n",
        "df2 = pd.DataFrame(df2, columns = ['commenttext','label'])\n",
        "\n",
        "data=pd.concat([df1,df2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BcZceS2vRPbj",
        "outputId": "77b38872-5810-4dd9-d9cd-a80e63f327bb"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>commenttext</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>// FIXME formatters are not thread-safe</td>\n",
              "      <td>Defect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>// XXX: (Jon Skeet) The comment \"if it hasn't ...</td>\n",
              "      <td>Defect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>// I hate to admit it, but we don't know what ...</td>\n",
              "      <td>Defect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>// Just a note: StarTeam has a status for NEW ...</td>\n",
              "      <td>Defect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>// the generated classes must not be added in ...</td>\n",
              "      <td>Defect</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         commenttext   label\n",
              "0            // FIXME formatters are not thread-safe  Defect\n",
              "1  // XXX: (Jon Skeet) The comment \"if it hasn't ...  Defect\n",
              "2  // I hate to admit it, but we don't know what ...  Defect\n",
              "3  // Just a note: StarTeam has a status for NEW ...  Defect\n",
              "4  // the generated classes must not be added in ...  Defect"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hUCRlzU8QXj0"
      },
      "source": [
        "# data.drop([\"Confident\",\"ï»¿ID\"],\n",
        "#           axis=1,\n",
        "#           inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dJ7u8CqZRcvg"
      },
      "source": [
        "data = np.asarray(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mGU7lIXNeetl"
      },
      "source": [
        "Label = data[:,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uKvxx27KekaN",
        "outputId": "55e7757b-f7be-4cac-dd7d-6ea50102d8c7"
      },
      "source": [
        "Label"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Defect', 'Defect', 'Defect', ..., 'Requirement', 'Defect',\n",
              "       'Defect'], dtype=object)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "B5nn_844QZRx",
        "outputId": "2499d418-7c61-41eb-d52f-9cace5df4caf"
      },
      "source": [
        "def labels_counters(data):\n",
        "  RE= 0\n",
        "  DEF = 0\n",
        "  DES = 0\n",
        "  DOC = 0\n",
        "  TEST = 0\n",
        "  Other = 0\n",
        " \n",
        "  for i in data:\n",
        "    if (i[1]== 'IMPLEMENTATION'):\n",
        "      RE += 1\n",
        "    if (i[1]== 'DEFECT'):\n",
        "      DEF += 1\n",
        "    if (i[1]== 'DESIGN'):\n",
        "      DES += 1\n",
        "    if (i[1]== 'DOCUMENTATION'):\n",
        "      DOC += 1\n",
        "    if (i[1]== 'TEST'):\n",
        "      TEST += 1\n",
        "    if (i[1]== ' '):\n",
        "      Other += 1\n",
        "  print(\"RE = {} , DEF = {}  , DES = {} , DOC = {} , TEST = {} , Other = {}\".format(RE,DEF,DES,DOC,TEST,Other))\n",
        "\n",
        "labels_counters(data)\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RE = 0 , DEF = 0  , DES = 0 , DOC = 0 , TEST = 0 , Other = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Q0U7TN0pQ6wS",
        "outputId": "656d584e-22a7-4bf6-ff35-5f0015d7273e"
      },
      "source": [
        "labels_counters(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RE = 0 , DEF = 0  , DES = 0 , DOC = 0 , TEST = 0 , Other = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IeXwXxlNdh8m",
        "outputId": "316c0a96-0b0f-4074-f276-c159bd7cd4eb"
      },
      "source": [
        "data[1][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Defect'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rOR8cMyYQhI7"
      },
      "source": [
        "my_Label = ['RE ','DEF ','DES ','DOC ','TEST ','Other']\n",
        "\n",
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "\n",
        "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
        "    text = text.lower() # lowercase text\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
        "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
        "    text = re.sub('\\d','', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "def get_wordnet_pos(word):\n",
        "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\n",
        "count = 0\n",
        "\n",
        "def lematizer_sentence(sentence):\n",
        "    # split into words\n",
        "    tokenize = word_tokenize(sentence)\n",
        "    \n",
        "    # convert to lower case\n",
        "    tokenize = [w.lower() for w in tokenize]\n",
        "    \n",
        "    # remove punctuation from each word\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    stripped = [w.translate(table) for w in tokenize]\n",
        "    \n",
        "    # remove remaining tokens that are not alphabetic\n",
        "    req_words = [word for word in stripped if word.isalpha()]\n",
        "    stop_words = stopwords.words('english')\n",
        "   \n",
        "    # filter out stop words\n",
        "    words = [w for w in req_words if not w in stop_words]\n",
        "    \n",
        "    \n",
        "    words = [WordNetLemmatizer().lemmatize(word, get_wordnet_pos(word)) for word in words]\n",
        "\n",
        "    return words\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FPUChtvX41nu"
      },
      "source": [
        "df = pd.DataFrame(data= data,columns=[\"classification\", \"commenttext\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RlMVOiMelXFH"
      },
      "source": [
        "colors = tuple([\"g\", \"SteelBlue\",\"r\",\"y\",\"m\",\"k\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dIHY1gd9NKvN"
      },
      "source": [
        "df['commenttext'] = df['commenttext'].apply(clean_text)\n",
        "df['commenttext'] = df['commenttext'].apply(lematizer_sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Fv42wxOYNMnO",
        "outputId": "893bad0d-4d58-4d84-f5af-731a0963aaac"
      },
      "source": [
        "len(df['commenttext'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5584"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cIMws8kMPpXH"
      },
      "source": [
        "import ast"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KnlC8680PyTG"
      },
      "source": [
        "dec = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vkr6gGFbNMj-"
      },
      "source": [
        "for sentence in df['commenttext']:\n",
        "  for word in sentence:\n",
        "   dec.append(word)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pbqinczrRMdS",
        "outputId": "70700b2f-b726-4c44-ec04-93db3ba8a447"
      },
      "source": [
        "len(dec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5584"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XsCDgstjVyoX"
      },
      "source": [
        "dec.sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GGV8LC0PV3CU"
      },
      "source": [
        "dec = (list(dict.fromkeys(dec)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gqKoSXKVW87z"
      },
      "source": [
        "def generate_bow(req_sentences,dec):    \n",
        "    # Define the BOW matrix\n",
        "    bag_vector = np.zeros((len(req_sentences), len(dec)))\n",
        "    # For each sentence\n",
        "    for j in range(len(req_sentences)):\n",
        "        # For each word within the sentence\n",
        "        for w in req_sentences[j]:\n",
        "            # For each word within the vocabulary\n",
        "            for i,word in enumerate(dec):\n",
        "                # If the word is in vocabulary, add 1 in position\n",
        "                if word == w: \n",
        "                    bag_vector[j,i] += 1\n",
        "    return bag_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PNdk98FMWqlp"
      },
      "source": [
        "BOW = generate_bow(df['commenttext'],dec)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FgOAM-Km8ZXv",
        "outputId": "11aab2f9-42db-43a4-be23-4eb093802785"
      },
      "source": [
        "print(len(BOW))\n",
        "print(BOW)\n",
        "print(df['commenttext'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5584\n",
            "[[1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]]\n",
            "0            [defect]\n",
            "1            [defect]\n",
            "2            [defect]\n",
            "3            [defect]\n",
            "4            [defect]\n",
            "            ...      \n",
            "5579    [requirement]\n",
            "5580         [design]\n",
            "5581    [requirement]\n",
            "5582         [defect]\n",
            "5583         [defect]\n",
            "Name: commenttext, Length: 5584, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "e9oQ-55I_f4I"
      },
      "source": [
        "from sklearn.svm import SVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eh5bhxZDSCCO"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import statistics\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "print(df.head(10))\n",
        "plt.figure(figsize=(10,4))\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "df.classification.value_counts().plot(kind='bar',color=colors);\n",
        "\n",
        "accuracy = []\n",
        "recall = [] \n",
        "precision = []\n",
        "f1 = []\n",
        "\n",
        "recall_total= [] \n",
        "precision_total = []\n",
        "f1_total = []\n",
        "\n",
        "\n",
        "\n",
        "for i in range(0,10):\n",
        "  x_train, x_test, y_train, y_test = train_test_split(BOW,Label, test_size=0.3)\n",
        "  x_train = np.array(x_train)\n",
        "  y_train = np.array(y_train)\n",
        "  x_test = np.array(x_test)\n",
        "  y_test = np.array(y_test)\n",
        "\n",
        "\n",
        "  svm_model = SVC()\n",
        "\n",
        "  svm_model.fit(x_train, y_train)\n",
        "  y_pred = svm_model.predict(x_test)\n",
        "  \n",
        "  accuracy.append( accuracy_score(y_pred, y_test))\n",
        "  print('accuracy %s' % accuracy_score(y_pred, y_test)) \n",
        "  precision.append(precision_score(y_pred, y_test,average=None,labels=my_Label))\n",
        "  recall.append(recall_score(y_pred, y_test,average=None,labels=my_Label))\n",
        "  f1.append(f1_score(y_pred, y_test,average=None,labels=my_Label))\n",
        "  precision_total.append(precision_score(y_pred, y_test,average=\"micro\"))\n",
        "  recall_total.append(recall_score(y_pred, y_test,average='micro'))\n",
        "  f1_total.append(f1_score(y_pred, y_test,average='micro'))\n",
        "\n",
        "\n",
        "statistics.mean(accuracy)\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3Wi8P4pSqst"
      },
      "source": [
        "statistics.mean(accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCsoPP3cfS9_"
      },
      "source": [
        "len(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy8M3uMBfXrc"
      },
      "source": [
        "len(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsTBqc84fa3k"
      },
      "source": [
        "872 + 375"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62Ne7Llpjsbj"
      },
      "source": [
        "print(classification_report(y_test, y_pred,target_names=my_Label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW4fM_3Jli9g"
      },
      "source": [
        "for x in accuracy:\n",
        "  print (x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l84Zgi5grCBY"
      },
      "source": [
        "for x in precision_total:\n",
        "  print(x)\n",
        "\n",
        "print(\"Mean = \",statistics.mean(precision_total))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_XrfVotrB-N"
      },
      "source": [
        "for x in recall_total:\n",
        "  print(x)\n",
        "\n",
        "print(\"Mean = \",statistics.mean(recall_total))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOeqgHyXrB7B"
      },
      "source": [
        "for x in f1_total:\n",
        "  print(x)\n",
        "\n",
        "print(\"Mean = \",statistics.mean(f1_total)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdspEO8HrB4O"
      },
      "source": [
        "def score_callculater(mat):\n",
        "  \n",
        "  all_class = []\n",
        "  us = []\n",
        "  for i in mat:\n",
        "    us.append(i[0])\n",
        "  all_class.append(statistics.mean(us))\n",
        "  \n",
        "  re = []\n",
        "  for i in mat:\n",
        "    re.append(i[1])\n",
        "  all_class.append(statistics.mean(re) ) \n",
        "\n",
        "  pe = []\n",
        "  for i in mat:\n",
        "    pe.append(i[2])\n",
        "  all_class.append(statistics.mean(pe)) \n",
        "\n",
        "  a = []\n",
        "  for i in mat:\n",
        "    a.append(i[3])\n",
        "  all_class.append(statistics.mean(a)) \n",
        "\n",
        "\n",
        "  se = []\n",
        "  for i in mat:\n",
        "    se.append(i[4])\n",
        "  all_class.append(statistics.mean(se))\n",
        "\n",
        "  other = []\n",
        "  for i in mat:\n",
        "    other.append(i[5])\n",
        "  all_class.append(statistics.mean(other))\n",
        "\n",
        "  return all_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsE8sOxhrB05"
      },
      "source": [
        "class_precision = score_callculater(precision)\n",
        "class_recall = score_callculater(recall)\n",
        "class_f1 = score_callculater(f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5XIGEtBrZye"
      },
      "source": [
        "for x in class_precision:\n",
        "  print(x)\n",
        "\n",
        "print(\"Avg \",statistics.mean(class_precision))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7TFAbbgrdAW"
      },
      "source": [
        "for x in class_recall:\n",
        "  print(x)\n",
        "print(\"Avg \",statistics.mean(class_recall))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CJeky87rf5m"
      },
      "source": [
        "for x in class_f1:\n",
        "  print(x)\n",
        "print(\"Avg \",statistics.mean(class_f1)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN0iqbcJrilV"
      },
      "source": [
        "x =0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO46-NHltZlQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}